**LLM-Scan** — это инструмент для анализа Python-библиотек. Он предотвращает атаки на цепочки поставок (Supply Chain Attacks), выявляя вредоносный код в пакетах PyPI еще до их установки в систему.

В отличие от статических сканеров, **LLM-Scan** использует семантический анализ с помощью нейросетей для поиска логических противоречий.

## Ключевые возможности

* Анализ исходного кода проводится без его запуска. Это защищает систему пользователя от вредоносных скриптов (например, `setup.py`).
* Архивы пакетов автоматически скачиваются и распаковываются во временной "песочнице".
* Удобная работа через алиас `pip-scan`, при котором вызов системы осуществляется с помощью одной команды в командной строке.

## Структура репозитория

* **pip_scan.py** — отвечает за загрузку пакетов и управление процессом.
* **scan.py** — модуль распаковки и взаимодействия с нейросетью.
* **promt.py** — содержит промт для ИИ.
* **alias.sh** — интеграция команды в терминал.
* **requirements.txt** — список необходимых зависимостей.

## Быстрый старт

### 1. Установка

```
git clone https://github.com/TheGuardianBaby/LLM-Scan.git
cd LLM-Scan
pip install -r requirements.txt
```

### 2. Активируйте алиас:

```source alias.sh```

### 3. Запустите анализ любого пакета:

```pip-scan <название_пакета>```

## Сценарии использования:

1. Оценка безопасности библиотек перед добавлением в проект.
2. Поиск вредоноса в малоизвестных или подозрительных программах.
3. Выявление вредоносных пакетов, замаскированных под популярные библиотеки (тайпсквоттинг).

**Автор:** [TheGuardianBaby](https://github.com/TheGuardianBaby)
